---
permalink: switch-netapp-cn1610/migrate-fas22xx-systems.html 
sidebar: sidebar 
keywords: migrate, two-node switched cluster, fas22xx systems, single, network connection 
summary: Wenn Sie FAS22xx-Systeme in einem bestehenden 2-Node-Cluster ohne Switches einsetzen, bei dem jedes Controller-Modul über eine einzelne, Back-to-Back-10-GbE-Verbindung für die Cluster-Konnektivität verfügt, können Sie die Cluster-Netzwerkoption ohne Switch verwenden und die direkte Back-to-Back-Konnektivität durch Switch-Verbindungen ersetzen. 
---
= Migration zu einem Switch-basierten 2-Node-Cluster in FAS22xx Systemen mit einer einzigen Cluster-Netzwerkverbindung
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Wenn Sie FAS22xx-Systeme in einem bestehenden 2-Node-Cluster ohne Switches einsetzen, bei dem jedes Controller-Modul über eine einzelne, Back-to-Back-10-GbE-Verbindung für die Cluster-Konnektivität verfügt, können Sie die Cluster-Netzwerkoption ohne Switch verwenden und die direkte Back-to-Back-Konnektivität durch Switch-Verbindungen ersetzen.



== Prüfen Sie die Anforderungen

.Bevor Sie beginnen
Stellen Sie sicher, dass Sie Folgendes haben:

* Zwei Cluster-Verbindungen für die Migration von einer Konfiguration ohne Switches zu einer Switched-Konfiguration.
* Das Cluster ist in einem ordnungsgemäßen Zustand und besteht aus zwei Nodes, die mit der Back-to-Back-Konnektivität verbunden sind.
* Auf den Knoten wird ONTAP 8.2 oder höher ausgeführt.
* Die Cluster-Funktion ohne Switch kann nicht mit mehr als zwei Nodes verwendet werden.
* Alle Cluster-Ports befinden sich im `up` Bundesland.


.Verwandte Informationen
https://kb.netapp.com/Advice_and_Troubleshooting/Data_Storage_Software/ONTAP_OS/How_to_suppress_automatic_case_creation_during_scheduled_maintenance_windows["NetApp KB Artikel 1010449: Wie kann die automatische Case-Erstellung während geplanter Wartungszeiten unterdrückt werden"^]



== Migrieren Sie die Switches

Bei diesem Verfahren wird die direkte Cluster-Konnektivität in einer Umgebung ohne Switches unterbrechungsfrei beseitigt und jede Verbindung zum Switch durch eine Verbindung zum Partner-Node ersetzt.



=== Schritt: Bereiten Sie sich auf die Migration vor

. Ändern Sie die Berechtigungsebene in erweitert, indem Sie eingeben `y` Wenn Sie dazu aufgefordert werden, fortzufahren:
+
`set -privilege advanced`

+
Die erweiterte Eingabeaufforderung (`*>`Erscheint.

. Überprüfen Sie den Cluster-Status der Nodes an der Systemkonsole eines der beiden Nodes:
+
`cluster show`

+
.Beispiel anzeigen
[%collapsible]
====
Im folgenden Beispiel werden Informationen über den Systemzustand und die Berechtigung der Nodes im Cluster angezeigt:

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Überprüfen Sie den Status des HA-Paars auf der Systemkonsole eines der beiden Nodes: `storage failover show`
+
.Beispiel anzeigen
[%collapsible]
====
Das folgende Beispiel zeigt den Status von node1 und node2:

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Wenn AutoSupport in diesem Cluster aktiviert ist, unterdrücken Sie die automatische Erstellung eines Falls durch Aufrufen einer AutoSupport Meldung:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
`x` Dies ist die Dauer des Wartungsfensters von Stunden.

+

NOTE: Die Meldung wird vom technischen Support dieser Wartungsaufgabe benachrichtigt, damit während des Wartungsfensters die automatische Case-Erstellung unterdrückt wird.

+
.Beispiel anzeigen
[%collapsible]
====
Mit dem folgenden Befehl wird die automatische Case-Erstellung für zwei Stunden unterdrückt:

[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=2h
----
====
. Vergewissern Sie sich, dass sich der aktuelle Status des Clusters ohne Switches befindet `true`, Und deaktivieren Sie dann den Cluster-Modus ohne Switches:
+
`network options switchless-cluster modify -enabled false`

. Übernehmen des Ziel-Node:
+
`storage failover takeover -ofnode _target_node_name_`

+
Es ist unerheblich, welcher Node der Ziel-Node ist. Nachdem der Ziel-Node übernommen wurde, wird er automatisch neu gebootet, und es wird angezeigt `Waiting for giveback...` Nachricht:

+
Der aktive Node stellt jetzt Daten für den über den Partner (Ziel)-Node bereit.

. Warten Sie zwei Minuten nach der Übernahme des beeinträchtigten Knotens, um zu bestätigen, dass die Übernahme erfolgreich abgeschlossen wurde.
. Wenn der Zielknoten das zeigt `Waiting for giveback...` Nachricht, Herunterfahren.
+
Die Methode zum Herunterfahren des Node hängt davon ab, ob Sie Remote-Management über den Node Service Processor (SP) verwenden.

+
|===
| Wenn SP | Dann... 


 a| 
Ist konfiguriert
 a| 
Melden Sie sich beim SP des beeinträchtigten Knotens an, und schalten Sie das System aus: `system power off`



 a| 
Ist nicht konfiguriert
 a| 
Drücken Sie an der Eingabeaufforderung für beeinträchtigte Knoten die Taste `Ctrl-C`, Und dann antworten `y` Zum Anhalten des Knotens.

|===




=== Schritt: Kabel und Ports konfigurieren

. Trennen Sie an jedem Controller-Modul das Kabel, das den 10-GbE-Cluster-Port mit dem Cluster ohne Switches verbindet.
. Verbinden Sie den 10 GbE-Cluster-Port mit dem Switch beider Controller-Module.
. Vergewissern Sie sich, dass die 10-GbE-Cluster-Ports, die auf dem Switch verbunden sind, als Teil desselben VLANs konfiguriert sind.
+
Wenn Sie die Cluster-Ports an jedem Controller-Modul mit unterschiedlichen Switches verbinden möchten, müssen Sie überprüfen, ob die Ports, an denen die Cluster-Ports an jedem Switch angeschlossen sind, für dasselbe VLAN konfiguriert sind und dass das Trunking auf beiden Switches ordnungsgemäß konfiguriert ist.

. Geben Sie dem Ziel-Node Storage zurück:
+
`storage failover giveback -ofnode node2`

. Überwachen Sie den Status des Giveback-Vorgangs:
+
`storage failover show-giveback`

. Nach Abschluss des Giveback-Vorgangs bestätigen Sie, dass das HA-Paar ordnungsgemäß funktioniert und ein Takeover möglich ist:
+
`storage failover show`

+
.Beispiel anzeigen
[%collapsible]
====
Die Ausgabe sollte wie folgt aussehen:

[listing]
----

Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------------
node1          node2          true      Connected to node2
node2          node1          true      Connected to node1

2 entries were displayed.
----
====
. Überprüfen Sie, ob die Cluster-Port-LIFs ordnungsgemäß funktionieren:
+
`network interface show -role cluster`

+
.Beispiel anzeigen
[%collapsible]
====
Das folgende Beispiel zeigt, dass die LIFs sind `up` Auf node1 und node2 und dass die "is Home" Spalte Ergebnisse sind `true`:

[listing]
----

cluster::*> network interface show -role cluster
            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
node1
            clus1        up/up    192.168.177.121/24  node1        e1a     true
node2
            clus1        up/up    192.168.177.123/24  node2        e1a     true

2 entries were displayed.
----
====
. Überprüfen Sie den Cluster-Status der Nodes an der Systemkonsole eines der beiden Nodes:
+
`cluster show`

+
.Beispiel anzeigen
[%collapsible]
====
Im folgenden Beispiel werden Informationen über den Systemzustand und die Berechtigung der Nodes im Cluster angezeigt:

[listing]
----

cluster::*> cluster show
Node                 Health  Eligibility   Epsilon
-------------------- ------- ------------  ------------
node1                true    true          false
node2                true    true          false

2 entries were displayed.
----
====
. Überprüfen Sie die Konnektivität der Remote-Cluster-Schnittstellen:


[role="tabbed-block"]
====
.ONTAP 9.9.1 und höher
--
Sie können das verwenden `network interface check cluster-connectivity` Befehl, um eine Zugriffsprüfung für die Cluster-Konnektivität zu starten und dann Details anzuzeigen:

`network interface check cluster-connectivity start` Und `network interface check cluster-connectivity show`

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity start*
----
*HINWEIS:* Warten Sie einige Sekunden, bevor Sie den Befehl ausführen `show`, um die Details anzuzeigen.

[listing, subs="+quotes"]
----
cluster1::*> *network interface check cluster-connectivity show*
                                  Source           Destination      Packet
Node   Date                       LIF              LIF              Loss
------ -------------------------- ---------------- ---------------- -----------
node1
       3/5/2022 19:21:18 -06:00   node1_clus2      node2-clus1      none
       3/5/2022 19:21:20 -06:00   node1_clus2      node2_clus2      none
node2
       3/5/2022 19:21:18 -06:00   node2_clus2      node1_clus1      none
       3/5/2022 19:21:20 -06:00   node2_clus2      node1_clus2      none
----
--
.Alle ONTAP Versionen
--
Sie können für alle ONTAP Versionen auch den verwenden `cluster ping-cluster -node <name>` Befehl zum Überprüfen der Konnektivität:

`cluster ping-cluster -node <name>`

[listing, subs="+quotes"]
----
cluster1::*> *cluster ping-cluster -node local*
Host is node2
Getting addresses from network interface table...
Cluster node1_clus1 169.254.209.69 node1 e0a
Cluster node1_clus2 169.254.49.125 node1 e0b
Cluster node2_clus1 169.254.47.194 node2 e0a
Cluster node2_clus2 169.254.19.183 node2 e0b
Local = 169.254.47.194 169.254.19.183
Remote = 169.254.209.69 169.254.49.125
Cluster Vserver Id = 4294967293
Ping status:....
Basic connectivity succeeds on 4 path(s)
Basic connectivity fails on 0 path(s)
................
Detected 9000 byte MTU on 4 path(s):
Local 169.254.47.194 to Remote 169.254.209.69
Local 169.254.47.194 to Remote 169.254.49.125
Local 169.254.19.183 to Remote 169.254.209.69
Local 169.254.19.183 to Remote 169.254.49.125
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
----
--
====


=== Schritt 3: Führen Sie den Vorgang durch

. Wenn Sie die automatische Erstellung eines Cases unterdrückten, können Sie sie erneut aktivieren, indem Sie eine AutoSupport Meldung aufrufen:
+
`system node autosupport invoke -node * -type all -message MAINT=END`

+
.Beispiel anzeigen
[%collapsible]
====
[listing]
----
cluster::*> system node autosupport invoke -node * -type all -message MAINT=END
----
====
. Ändern Sie die Berechtigungsebene zurück in den Administrator:
+
`set -privilege admin`


