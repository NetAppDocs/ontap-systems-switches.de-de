---
permalink: switch-nvidia-sn2100/replace_sn2100_switch_cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nvidia, switch, cluster, network, nondisruptive, procedure, ndu, replace a nvidia msn2100 cluster switch - nvidia SN2100 
summary: 'Der Austausch eines defekten NVIDIA SN2100-Switches in einem Cluster-Netzwerk ist ein unterbrechungsfreies Verfahren \(NDU\).' 
---
= Ersetzen Sie einen NVIDIA SN2100-Cluster-Switch
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Der Austausch eines fehlerhaften NVIDIA SN2100-Switches in einem Cluster-Netzwerk ist ein NDU.

Die folgenden Bedingungen müssen vorliegen, bevor der Switch in der aktuellen Umgebung und am Ersatzschalter ausgetauscht wird.

* Vorhandene Cluster- und Netzwerkinfrastruktur:
+
** Das vorhandene Cluster muss mit mindestens einem vollständig verbundenen Cluster-Switch als voll funktionsfähig verifiziert werden.
** Alle Cluster-Ports müssen aktiv sein.
** Alle logischen Cluster-Schnittstellen (LIFs) müssen sich und an ihren Home-Ports befinden.
** Das ONTAP `cluster ping-cluster -node node1` Der Befehl muss angeben, dass grundlegende und größere Verbindungen als die PMTU-Kommunikation auf allen Pfaden erfolgreich sind.


* NVIDIA SN2100-Ersatzschalter:
+
** Die Konnektivität des Managementnetzwerks am Ersatz-Switch muss funktionsfähig sein.
** Der Konsolenzugriff auf den Ersatzschalter muss vorhanden sein.
** Die Knotenverbindungen sind die Anschlüsse swp1 bis swp14.
** Alle Inter-Switch Link (ISL)-Ports müssen an den Ports swp15 und swp16 deaktiviert sein.
** Die gewünschte Referenzkonfigurationsdatei (RCF) und der Bildschalter des Betriebssystems Cumulus müssen auf den Switch geladen werden.
** Die ursprüngliche Anpassung des Schalters muss abgeschlossen sein, wie in beschrieben:
+
Alle zuvor erstellten Site-Anpassungen wie STP, SNMP und SSH sollten auf den neuen Switch kopiert werden.





Sie müssen den Befehl zum Migrieren einer Cluster-LIF von dem Node ausführen, auf dem die Cluster-LIF gehostet wird.

Die Beispiele in diesem Verfahren verwenden die folgende Nomenklatur für Switches und Knoten:

* Die Namen der vorhandenen NVIDIA SN2100-Switches lauten _sw1_ und _sw2_.
* Der Name des neuen NVIDIA SN2100 Switch lautet _nsw2_.
* Die Knotennamen sind _node1_ und _node2_.
* Die Cluster-Ports auf jedem Node lauten _e3a_ und _e3b_.
* Die Cluster LIF-Namen sind _node1_clus1_ und _node1_clus2_ für node1, und _node2_clus1_ und _node2_clus2_ für node2.
* Die Eingabeaufforderung für Änderungen an allen Cluster-Nodes lautet `cluster1::*>`
* Breakout-Ports haben das Format swp[Port]s[Breakout-Port 0-3]. Beispielsweise sind vier Breakout-Ports auf swp1 _swp1s0_, _swp1s1_, _swp1s2_ und _swp1s3_.
+

NOTE: Die folgende Vorgehensweise basiert auf der folgenden Cluster-Netzwerktopologie:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true


cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw2                e3a
swp4       100G   Trunk/L2    sw2                e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16


cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw1                e3b
swp4       100G   Trunk/L2    sw1                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----


.Schritte
. Wenn AutoSupport in diesem Cluster aktiviert ist, unterdrücken Sie die automatische Erstellung eines Falls durch Aufrufen einer AutoSupport Meldung: `system node autosupport invoke -node * -type all -message MAINT=xh`
+
Wobei _x_ die Dauer des Wartungsfensters in Stunden ist.

. Ändern Sie die Berechtigungsebene in Erweitert, und geben Sie *y* ein, wenn Sie dazu aufgefordert werden, fortzufahren: `set -privilege advanced`
+
Die erweiterte Eingabeaufforderung (*>) wird angezeigt.

. Installieren Sie das entsprechende RCF und das entsprechende Image auf dem Switch, nsw2, und treffen Sie die erforderlichen Standortvorbereitungen.
+
Überprüfen, laden und installieren Sie gegebenenfalls die entsprechenden Versionen der RCF- und Cumulus-Software für den neuen Switch. Wenn Sie überprüft haben, dass der neue Schalter richtig eingerichtet ist und keine Aktualisierungen der RCF- und Cumulus-Software benötigt, fahren Sie mit Schritt 4 fort. Siehe link:install_setup_sn2100_switches_overview.html["Einrichten und Konfigurieren der NVIDIA SN2100-Switches"] Entnehmen.

+
.. Sie können die entsprechende Cumulus-Software für Ihre Cluster-Switches von der Seite _NVIDIA Support_ herunterladen. Folgen Sie den Schritten auf der Download-Seite, um das Cumulus Linux für die Version der ONTAP Software, die Sie installieren, herunterzuladen.
.. Das entsprechende RCF ist im erhältlich link:https://mysupport.netapp.com/site/products/all/details/nvidia-cluster-storage-switch/downloads-tab["_NVIDIA Cluster und Storage Switches_"^] Seite. Befolgen Sie die Schritte auf der Download-Seite, um den korrekten RCF für die Version der von Ihnen installierenden ONTAP-Software herunterzuladen.


. Melden Sie sich beim neuen Switch nsw2 als admin an und fahren Sie alle Ports herunter, die mit den Node-Cluster-Schnittstellen verbunden werden (Ports swp1 bis swp14).
+
Wenn der Schalter, den Sie ersetzen, nicht funktionsfähig ist und ausgeschaltet ist, fahren Sie mit Schritt 5 fort. Die LIFs auf den Cluster-Nodes sollten für jeden Node bereits ein Failover auf den anderen Cluster-Port durchgeführt haben.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Deaktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs: `network interface modify -vserver Cluster -lif * -auto-revert false`
+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Schließen Sie die ISL-Ports swp15 und swp16 am SN2100-Switch sw1:
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
. Entfernen Sie alle Kabel vom SN2100 sw1-Switch, und verbinden Sie sie dann mit den gleichen Ports am SN2100 nsw2-Switch.
. Die ISL-Ports swp15 und swp16 zwischen den Switches sw1 und nsw2.
+
Die folgenden Befehle ermöglichen ISL-Ports swp15 und swp16 auf Switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch sw1 aufstehen:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch nsw2 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Überprüfen Sie diesen Port `e3b` Ist auf allen Knoten aktiv: `network port show -ipspace Cluster`
+
Die Ausgabe sollte wie folgt aussehen:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Die Cluster-Ports auf jedem Node sind nun aus Sicht der Nodes mit Cluster-Switches auf die folgende Weise verbunden:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Vergewissern Sie sich, dass alle Node-Cluster-Ports aktiv sind: `net show interface`
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Vergewissern Sie sich, dass beide Knoten jeweils eine Verbindung zu jedem Switch haben: `net show lldp`
+
Das folgende Beispiel zeigt die entsprechenden Ergebnisse für beide Switches:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Aktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs: `cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`
. Bringen Sie auf Switch nsw2 die Ports an, die mit den Netzwerkports der Knoten verbunden sind.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net del interface swp1-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Zeigen Sie Informationen über die Nodes in einem Cluster an: `cluster show`
+
Dieses Beispiel zeigt, dass der Zustand des Node für Node 1 und node2 in diesem Cluster „true“ lautet:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Vergewissern Sie sich, dass alle physischen Cluster-Ports aktiv sind: `network port show ipspace Cluster`
+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false

----
. Vergewissern Sie sich, dass das Cluster-Netzwerk ordnungsgemäß ist:
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----
. Aktivieren Sie die Protokollerfassungsfunktion für die Ethernet Switch-Systemzustandsüberwachung mithilfe der Befehle, um Switch-bezogene Protokolldateien zu erfassen: `system switch ethernet log setup-password` Und `system switch ethernet log enable-collection`
+
Geben Sie Ein: `system switch ethernet log setup-password`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log setup-password*
Enter the switch name: <return>
The switch name entered is not recognized.
Choose from the following list:
*sw1*
*nsw2*

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *sw1*
RSA key fingerprint is e5:8b:c6:dc:e2:18:18:09:36:63:d9:63:dd:03:d9:cc
Do you want to continue? {y|n}::[n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>

cluster1::*> *system switch ethernet log setup-password*

Enter the switch name: *nsw2*
RSA key fingerprint is 57:49:86:a1:b9:80:6a:61:9a:86:8e:3c:e3:b7:1f:b1
Do you want to continue? {y|n}:: [n] *y*

Enter the password: <enter switch password>
Enter the password again: <enter switch password>
----
+
Gefolgt von: `system switch ethernet log enable-collection`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log enable-collection*

Do you want to enable cluster log collection for all nodes in the cluster?
{y|n}: [n] *y*

Enabling cluster switch log collection.

cluster1::*>
----
+

NOTE: Wenn einer dieser Befehle einen Fehler sendet, wenden Sie sich an den NetApp Support.

. Initiieren der Switch-Protokollerfassung: `system switch ethernet log collect -device *`
+
Warten Sie 10 Minuten, und überprüfen Sie dann, ob die Protokollsammlung erfolgreich war mit dem folgenden Befehl: `system switch ethernet log show`

+
[listing, subs="+quotes"]
----
cluster1::*> *system switch ethernet log show*
Log Collection Enabled: true

Index  Switch                       Log Timestamp        Status
------ ---------------------------- -------------------  ---------    
1      sw1 (b8:ce:f6:19:1b:42)      4/29/2022 03:05:25   complete   
2      nsw2 (b8:ce:f6:19:1b:96)     4/29/2022 03:07:42   complete
----
. Ändern Sie die Berechtigungsebene zurück in den Administrator: `set -privilege admin`
. Wenn Sie die automatische Case-Erstellung unterdrückt haben, aktivieren Sie es erneut, indem Sie eine AutoSupport Meldung aufrufen: `system node autosupport invoke -node * -type all -message MAINT=END`

