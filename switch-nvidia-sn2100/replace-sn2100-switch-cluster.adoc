---
permalink: switch-nvidia-sn2100/replace-sn2100-switch-cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nvidia, switch, cluster, network, nondisruptive, procedure, ndu, replace a nvidia msn2100 cluster switch - nvidia SN2100 
summary: 'Der Austausch eines defekten NVIDIA SN2100-Switches in einem Clusternetzwerk ist ein nicht-unterbrechendes Verfahren (NDU).' 
---
= Ersetzen Sie einen NVIDIA SN2100 Cluster-Switch
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Gehen Sie wie folgt vor, um einen defekten NVIDIA SN2100-Switch in einem Clusternetzwerk auszutauschen. Dies ist ein unterbrechungsfreies Verfahren (NDU).



== Überprüfungsanforderungen

.Vorhandene Cluster- und Netzwerkinfrastruktur
Stellen Sie sicher, dass:

* Es wurde überprüft, dass die vorhandenen Cluster voll funktionsfähig sind und mindestens ein Cluster-Switch vollständig angeschlossen ist.
* Alle Cluster-Ports sind aktiv.
* Alle logischen Schnittstellen (LIFs) des Clusters sind aktiv und an ihren jeweiligen Ports angeschlossen.
* Das ONTAP `cluster ping-cluster -node node1` Der Befehl zeigt an, dass die grundlegende Konnektivität und die Kommunikation über PMTU hinaus auf allen Pfaden erfolgreich sind.


.NVIDIA SN2100 Ersatzschalter
Stellen Sie sicher, dass:

* Die Management-Netzwerkanbindung des Ersatz-Switches ist funktionsfähig.
* Der Konsolenzugriff auf den Ersatzschalter ist eingerichtet.
* Die Knotenverbindungen sind die Ports swp1 bis swp14.
* Alle Inter-Switch Link (ISL)-Ports sind an den Ports swp15 und swp16 deaktiviert.
* Die gewünschte Referenzkonfigurationsdatei (RCF) und das Cumulus-Betriebssystem-Image werden auf den Switch geladen.
* Die erste Konfiguration des Schalters ist abgeschlossen.


Achten Sie außerdem darauf, dass alle zuvor vorgenommenen Anpassungen am Standort, wie z. B. STP, SNMP und SSH, auf den neuen Switch kopiert werden.


NOTE: Sie müssen den Befehl zur Migration eines Cluster-LIF von dem Knoten ausführen, auf dem der Cluster-LIF gehostet wird.



== Konsolenprotokollierung aktivieren

NetApp empfiehlt dringend, die Konsolenprotokollierung auf den verwendeten Geräten zu aktivieren und beim Austausch Ihres Switches die folgenden Maßnahmen zu ergreifen:

* Lassen Sie AutoSupport während der Wartungsarbeiten aktiviert.
* Lösen Sie vor und nach der Wartung einen Wartungs AutoSupport aus, um die Fallerstellung für die Dauer der Wartung zu deaktivieren.  Siehe diesen Wissensdatenbankartikel https://kb.netapp.com/Support_Bulletins/Customer_Bulletins/SU92["SU92: Wie man die automatische Fallerstellung während geplanter Wartungsfenster unterdrückt"^] für weitere Einzelheiten.
* Aktivieren Sie die Sitzungsprotokollierung für alle CLI-Sitzungen.  Anweisungen zum Aktivieren der Sitzungsprotokollierung finden Sie im Abschnitt „Protokollierung der Sitzungsausgabe“ in diesem Wissensdatenbankartikel. https://kb.netapp.com/on-prem/ontap/Ontap_OS/OS-KBs/How_to_configure_PuTTY_for_optimal_connectivity_to_ONTAP_systems["Wie konfiguriert man PuTTY für eine optimale Verbindung zu ONTAP -Systemen?"^] Die




== Tauschen Sie den Schalter aus.

.Zu den Beispielen
Die Beispiele in diesem Verfahren verwenden die folgende Schalter- und Knotennomenklatur:

* Die Namen der vorhandenen NVIDIA SN2100-Switches lauten _sw1_ und _sw2_.
* Der Name des neuen NVIDIA SN2100 Switches lautet _nsw2_.
* Die Knotennamen lauten _node1_ und _node2_.
* Die Cluster-Ports auf jedem Knoten tragen die Namen _e3a_ und _e3b_.
* Die Cluster-LIF-Namen lauten _node1_clus1_ und _node1_clus2_ für Knoten 1 sowie _node2_clus1_ und _node2_clus2_ für Knoten 2.
* Die Aufforderung zur Änderung aller Clusterknoten lautet: `cluster1::*>`
* Breakout-Ports haben folgendes Format: swp[Port]s[Breakout-Port 0-3].  Beispielsweise gibt es vier Breakout-Ports auf swp1: _swp1s0_, _swp1s1_, _swp1s2_ und _swp1s3_.


.Über die Cluster-Netzwerktopologie
Dieses Verfahren basiert auf folgender Cluster-Netzwerktopologie:

.Beispieltopologie anzeigen
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true


cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
+

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw2                e3a
swp4       100G   Trunk/L2    sw2                e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16


cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw1                e3b
swp4       100G   Trunk/L2    sw1                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
====


=== Schritt 1: Vorbereitung auf den Austausch

. Wenn AutoSupport auf diesem Cluster aktiviert ist, unterdrücken Sie die automatische Fallerstellung durch Aufruf einer AutoSupport -Nachricht:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
wobei _x_ die Dauer des Wartungsfensters in Stunden ist.

. Ändern Sie die Berechtigungsstufe auf „Erweitert“, indem Sie *y* eingeben, wenn Sie zur Fortsetzung aufgefordert werden:
+
`set -privilege advanced`

+
Die erweiterte Eingabeaufforderung (*>) wird angezeigt.

. Installieren Sie die entsprechende RCF-Datei und das Image auf dem Switch nsw2 und treffen Sie alle notwendigen Vorbereitungen vor Ort.
+
Prüfen, laden und installieren Sie gegebenenfalls die entsprechenden Versionen der RCF- und Cumulus-Software für den neuen Switch.

+
.. Sie können die passende Cumulus-Software für Ihre Cluster-Switches von der NVIDIA Support-Website herunterladen.  Folgen Sie den Anweisungen auf der Downloadseite, um Cumulus Linux für die Version der ONTAP -Software herunterzuladen, die Sie installieren.
.. Die entsprechende RCF ist erhältlich bei derlink:https://mysupport.netapp.com/site/products/all/details/nvidia-cluster-storage-switch/downloads-tab["NVIDIA Cluster- und Speicher-Switches"^] Seite.  Folgen Sie den Anweisungen auf der Downloadseite, um die richtige RCF-Datei für die Version der ONTAP -Software herunterzuladen, die Sie installieren.






=== Schritt 2: Anschlüsse und Verkabelung konfigurieren

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Melden Sie sich auf dem neuen Switch nsw2 als Administrator an und deaktivieren Sie alle Ports, die mit den Schnittstellen des Knotenclusters verbunden werden (Ports swp1 bis swp14).
+
Die LIFs auf den Clusterknoten sollten bereits für jeden Knoten auf den anderen Clusterport umgeschaltet haben.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Automatische Wiederherstellung der Cluster-LIFs deaktivieren:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Überprüfen Sie, ob die automatische Rücksetzung für alle Cluster-LIFs deaktiviert ist:
+
`net interface show -vserver Cluster -fields auto-revert`

. Schalten Sie die ISL-Ports swp15 und swp16 am SN2100-Switch sw1 ab.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
. Entfernen Sie alle Kabel vom SN2100 sw1 Switch und schließen Sie sie dann an die gleichen Ports am SN2100 nsw2 Switch an.
. Aktivieren Sie die ISL-Ports swp15 und swp16 zwischen den Switches sw1 und nsw2.
+
Die folgenden Befehle aktivieren die ISL-Ports swp15 und swp16 auf Switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports am Switch sw1 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch nsw2 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Überprüfen Sie, ob der Port `e3b` ist auf allen Knoten aktiv:
+
`network port show -ipspace Cluster`

+
Die Ausgabe sollte in etwa wie folgt aussehen:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Die Cluster-Ports auf jedem Knoten sind nun, aus Sicht der Knoten, folgendermaßen mit den Cluster-Switches verbunden:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Überprüfen Sie, ob alle Ports des Knotenclusters aktiv sind:
+
`net show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Überprüfen Sie, ob beide Knoten jeweils eine Verbindung zu jedem Switch haben:
+
`net show lldp`

+
Das folgende Beispiel zeigt die entsprechenden Ergebnisse für beide Schalter:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Automatische Wiederherstellung der Cluster-LIFs aktivieren:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Schalten Sie auf Switch nsw2 die Ports ein, die mit den Netzwerkports der Knoten verbunden sind.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net del interface swp1-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Informationen über die Knoten in einem Cluster anzeigen:
+
`cluster show`

+
Dieses Beispiel zeigt, dass der Knotenstatus für Knoten 1 und Knoten 2 in diesem Cluster „true“ ist:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Überprüfen Sie, ob alle physischen Cluster-Ports aktiv sind:
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
.Cumulus Linux 5.x
--
. Melden Sie sich auf dem neuen Switch nsw2 als Administrator an und deaktivieren Sie alle Ports, die mit den Schnittstellen des Knotenclusters verbunden werden (Ports swp1 bis swp14).
+
Die LIFs auf den Clusterknoten sollten bereits für jeden Knoten auf den anderen Clusterport umgeschaltet haben.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp15-16 link state down*
cumulus@nsw2:~$ *nv config apply*
----
. Automatische Wiederherstellung der Cluster-LIFs deaktivieren:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Überprüfen Sie, ob die automatische Rücksetzung für alle Cluster-LIFs deaktiviert ist:
+
`network interface show -vserver Cluster -fields auto-revert`

. Schalten Sie die ISL-Ports swp15 und swp16 am SN2100-Switch sw1 ab.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
. Entfernen Sie alle Kabel vom SN2100 sw1 Switch und schließen Sie sie dann an die gleichen Ports am SN2100 nsw2 Switch an.
. Aktivieren Sie die ISL-Ports swp15 und swp16 zwischen den Switches sw1 und nsw2.
+
Die folgenden Befehle aktivieren die ISL-Ports swp15 und swp16 auf Switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports am Switch sw1 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch nsw2 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Überprüfen Sie, ob der Port `e3b` ist auf allen Knoten aktiv:
+
`network port show -ipspace Cluster`

+
Die Ausgabe sollte in etwa wie folgt aussehen:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Die Cluster-Ports auf jedem Knoten sind nun, aus Sicht der Knoten, folgendermaßen mit den Cluster-Switches verbunden:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Überprüfen Sie, ob alle Ports des Knotenclusters aktiv sind:
+
`nv show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Überprüfen Sie, ob beide Knoten jeweils eine Verbindung zu jedem Switch haben:
+
`nv show interface lldp`

+
Das folgende Beispiel zeigt die entsprechenden Ergebnisse für beide Schalter:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Automatische Wiederherstellung der Cluster-LIFs aktivieren:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Schalten Sie auf Switch nsw2 die Ports ein, die mit den Netzwerkports der Knoten verbunden sind.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp1-14 link state up*
cumulus@nsw2:~$ *nv config apply*
----
. Informationen über die Knoten in einem Cluster anzeigen:
+
`cluster show`

+
Dieses Beispiel zeigt, dass der Knotenstatus für Knoten 1 und Knoten 2 in diesem Cluster „true“ ist:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Überprüfen Sie, ob alle physischen Cluster-Ports aktiv sind:
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
====


=== Schritt 3: Konfiguration überprüfen

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Überprüfen Sie, ob das Clusternetzwerk fehlerfrei funktioniert.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
.Cumulus Linux 5.x
--
. Überprüfen Sie, ob das Clusternetzwerk fehlerfrei funktioniert.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
====
. [[Schritt 2]] Ändern Sie die Berechtigungsstufe wieder auf Administrator:
+
`set -privilege admin`

. Wenn Sie die automatische Fallerstellung unterdrückt haben, können Sie sie durch Aufruf einer AutoSupport Nachricht wieder aktivieren:
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Wie geht es weiter?
Nachdem Sie Ihre Schalter ausgetauscht haben, können Sie link:../switch-cshm/config-overview.html["Konfigurieren der Switch-Integritätsüberwachung"]Die
