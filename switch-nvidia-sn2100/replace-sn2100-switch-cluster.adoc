---
permalink: switch-nvidia-sn2100/replace-sn2100-switch-cluster.html 
sidebar: sidebar 
keywords: replacing, replace, defective, nvidia, switch, cluster, network, nondisruptive, procedure, ndu, replace a nvidia msn2100 cluster switch - nvidia SN2100 
summary: 'Der Austausch eines defekten NVIDIA SN2100-Switches in einem Cluster-Netzwerk ist ein unterbrechungsfreies Verfahren \(NDU\).' 
---
= Ersetzen Sie einen NVIDIA SN2100-Cluster-Switch
:allow-uri-read: 
:icons: font
:imagesdir: ../media/


[role="lead"]
Gehen Sie folgendermaßen vor, um einen defekten NVIDIA SN2100-Switch in einem Cluster-Netzwerk zu ersetzen. Dies ist ein NDU (Non Disruptive Procedure, NDU).



== Prüfen Sie die Anforderungen

.Bestehende Cluster- und Netzwerkinfrastruktur
Stellen Sie sicher, dass:

* Das vorhandene Cluster wird mit mindestens einem vollständig verbundenen Cluster-Switch als voll funktionsfähig geprüft.
* Alle Cluster-Ports sind aktiv.
* Alle logischen Cluster-Schnittstellen (LIFs) laufen und auf ihren Home-Ports.
* Das ONTAP `cluster ping-cluster -node node1` Der Befehl gibt an, dass grundlegende und größere Verbindungen als PMTU auf allen Pfaden erfolgreich sind.


.NVIDIA SN2100-Ersatzschalter
Stellen Sie sicher, dass:

* Die Konnektivität des Managementnetzwerks am Ersatz-Switch funktioniert.
* Der Konsolenzugriff auf den Ersatz-Switch erfolgt.
* Die Knotenverbindungen sind die Anschlüsse swp1 bis swp14.
* Alle Inter-Switch Link (ISL)-Ports sind an den Ports swp15 und swp16 deaktiviert.
* Die gewünschte Referenzkonfigurationsdatei (RCF) und der Bildschalter des Betriebssystems Cumulus werden auf den Switch geladen.
* Die anfängliche Anpassung des Schalters ist abgeschlossen.


Vergewissern Sie sich außerdem, dass alle Änderungen an früheren Standorten, wie STP, SNMP und SSH, auf den neuen Switch kopiert werden.


NOTE: Sie müssen den Befehl zum Migrieren einer Cluster-LIF von dem Node ausführen, auf dem die Cluster-LIF gehostet wird.



== Aktivieren Sie die Konsolenprotokollierung

NetApp empfiehlt dringend, die Konsolenprotokollierung auf den verwendeten Geräten zu aktivieren und beim Austausch des Switches die folgenden Maßnahmen zu ergreifen:

* Lassen Sie AutoSupport während der Wartung aktiviert.
* Lösen Sie vor und nach der Wartung einen Wartungs-AutoSupport aus, um die Case-Erstellung für die Dauer der Wartung zu deaktivieren. Lesen Sie diesen Knowledge Base-Artikel https://kb.netapp.com/Support_Bulletins/Customer_Bulletins/SU92["SU92: Unterdrücken der automatischen Case-Erstellung während geplanter Wartungsfenster"^] Entnehmen.
* Aktivieren Sie die Sitzungsprotokollierung für beliebige CLI-Sitzungen. Anweisungen zum Aktivieren der Sitzungsprotokollierung finden Sie im Abschnitt „Protokollierung der Sitzungsausgabe“ in diesem Knowledge Base Artikel https://kb.netapp.com/on-prem/ontap/Ontap_OS/OS-KBs/How_to_configure_PuTTY_for_optimal_connectivity_to_ONTAP_systems["So konfigurieren Sie PuTTY für optimale Konnektivität zu ONTAP-Systemen"^].




== Tauschen Sie den Schalter aus

.Zu den Beispielen
Die Beispiele in diesem Verfahren verwenden die folgende Nomenklatur für Switches und Knoten:

* Die Namen der vorhandenen NVIDIA SN2100-Switches lauten _sw1_ und _sw2_.
* Der Name des neuen NVIDIA SN2100 Switch lautet _nsw2_.
* Die Knotennamen sind _node1_ und _node2_.
* Die Cluster-Ports auf jedem Node lauten _e3a_ und _e3b_.
* Die Cluster LIF-Namen sind _node1_clus1_ und _node1_clus2_ für node1, und _node2_clus1_ und _node2_clus2_ für node2.
* Die Eingabeaufforderung für Änderungen an allen Cluster-Nodes lautet `cluster1::*>`
* Breakout-Ports haben das Format swp[Port]s[Breakout-Port 0-3]. Beispielsweise sind vier Breakout-Ports auf swp1 _swp1s0_, _swp1s1_, _swp1s2_ und _swp1s3_.


.Allgemeines zur Cluster-Netzwerktopologie
Dieses Verfahren basiert auf der folgenden Cluster-Netzwerktopologie:

.Beispieltopologie anzeigen
[%collapsible]
====
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false

Node: node2
                                                                        Ignore
                                                  Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU  Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ---- ------------ -------- ------
e3a       Cluster      Cluster          up   9000  auto/100000 healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000 healthy  false


cluster1::*> *network interface show -vserver Cluster*

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
Cluster
            node1_clus1  up/up    169.254.209.69/16  node1         e3a     true
            node1_clus2  up/up    169.254.49.125/16  node1         e3b     true
            node2_clus1  up/up    169.254.47.194/16  node2         e3a     true
            node2_clus2  up/up    169.254.19.183/16  node2         e3b     true


cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp3          -
node2      /lldp
            e3a    sw1 (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    sw2 (b8:ce:f6:19:1b:96)   swp4          -
----
+

[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw2                e3a
swp4       100G   Trunk/L2    sw2                e3a
swp15      100G   BondMember  sw2                swp15
swp16      100G   BondMember  sw2                swp16


cumulus@sw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    sw1                e3b
swp4       100G   Trunk/L2    sw1                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
====


=== Schritt 1: Vorbereitung auf den Austausch

. Wenn AutoSupport in diesem Cluster aktiviert ist, unterdrücken Sie die automatische Erstellung eines Falls durch Aufrufen einer AutoSupport Meldung:
+
`system node autosupport invoke -node * -type all -message MAINT=xh`

+
Wobei _x_ die Dauer des Wartungsfensters in Stunden ist.

. Ändern Sie die Berechtigungsebene in Erweitert, und geben Sie *y* ein, wenn Sie dazu aufgefordert werden, fortzufahren:
+
`set -privilege advanced`

+
Die erweiterte Eingabeaufforderung (*>) wird angezeigt.

. Installieren Sie das entsprechende RCF und das entsprechende Image auf dem Switch, nsw2, und treffen Sie die erforderlichen Standortvorbereitungen.
+
Überprüfen, laden und installieren Sie gegebenenfalls die entsprechenden Versionen der RCF- und Cumulus-Software für den neuen Switch.

+
.. Sie können die entsprechende Cumulus-Software für Ihre Cluster-Switches von der Seite _NVIDIA Support_ herunterladen. Folgen Sie den Schritten auf der Download-Seite, um das Cumulus Linux für die Version der ONTAP Software, die Sie installieren, herunterzuladen.
.. Das entsprechende RCF ist im erhältlich link:https://mysupport.netapp.com/site/products/all/details/nvidia-cluster-storage-switch/downloads-tab["_NVIDIA Cluster und Storage Switches_"^] Seite. Befolgen Sie die Schritte auf der Download-Seite, um den korrekten RCF für die Version der von Ihnen installierenden ONTAP-Software herunterzuladen.






=== Schritt: Ports und Verkabelung konfigurieren

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Melden Sie sich beim neuen Switch nsw2 als admin an und fahren Sie alle Ports herunter, die mit den Node-Cluster-Schnittstellen verbunden werden (Ports swp1 bis swp14).
+
Die LIFs auf den Cluster-Nodes sollten für jeden Node bereits ein Failover auf den anderen Cluster-Port durchgeführt haben.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net add interface swp1s0-3, swp2s0-3, swp3-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Deaktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Stellen Sie sicher, dass die automatische Rücksetzung bei allen Cluster-LIFs deaktiviert ist:
+
`net interface show -vserver Cluster -fields auto-revert`

. Schließen Sie die ISL-Ports swp15 und swp16 am SN2100-Switch sw1 ab.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net add interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
. Entfernen Sie alle Kabel vom SN2100 sw1-Switch, und verbinden Sie sie dann mit den gleichen Ports am SN2100 nsw2-Switch.
. Die ISL-Ports swp15 und swp16 zwischen den Switches sw1 und nsw2.
+
Die folgenden Befehle ermöglichen ISL-Ports swp15 und swp16 auf Switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net del interface swp15-16 link down*
cumulus@sw1:~$ *net pending*
cumulus@sw1:~$ *net commit*
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch sw1 aufstehen:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch nsw2 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Überprüfen Sie diesen Port `e3b` Ist auf allen Knoten aktiv:
+
`network port show -ipspace Cluster`

+
Die Ausgabe sollte wie folgt aussehen:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Die Cluster-Ports auf jedem Node sind nun aus Sicht der Nodes mit Cluster-Switches auf die folgende Weise verbunden:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Vergewissern Sie sich, dass alle Node-Cluster-Ports aktiv sind:
+
`net show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Vergewissern Sie sich, dass beide Knoten jeweils eine Verbindung zu jedem Switch haben:
+
`net show lldp`

+
Das folgende Beispiel zeigt die entsprechenden Ergebnisse für beide Switches:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Aktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Bringen Sie auf Switch nsw2 die Ports an, die mit den Netzwerkports der Knoten verbunden sind.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *net del interface swp1-14 link down*
cumulus@nsw2:~$ *net pending*
cumulus@nsw2:~$ *net commit*
----
. Zeigen Sie Informationen über die Nodes in einem Cluster an:
+
`cluster show`

+
Dieses Beispiel zeigt, dass der Zustand des Node für Node 1 und node2 in diesem Cluster „true“ lautet:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Vergewissern Sie sich, dass alle physischen Cluster-Ports aktiv sind:
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
.Cumulus Linux 5.x
--
. Melden Sie sich beim neuen Switch nsw2 als admin an und fahren Sie alle Ports herunter, die mit den Node-Cluster-Schnittstellen verbunden werden (Ports swp1 bis swp14).
+
Die LIFs auf den Cluster-Nodes sollten für jeden Node bereits ein Failover auf den anderen Cluster-Port durchgeführt haben.

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp15-16 link state down*
cumulus@nsw2:~$ *nv config apply*
----
. Deaktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs:
+
`network interface modify -vserver Cluster -lif * -auto-revert false`

+
[listing, subs="+quotes"]
----
cluster1::*> *network interface modify -vserver Cluster -lif * -auto-revert false*

Warning: Disabling the auto-revert feature of the cluster logical interface may effect the availability of your cluster network. Are you sure you want to continue? {y|n}: *y*
----
. Stellen Sie sicher, dass die automatische Rücksetzung bei allen Cluster-LIFs deaktiviert ist:
+
`network interface show -vserver Cluster -fields auto-revert`

. Schließen Sie die ISL-Ports swp15 und swp16 am SN2100-Switch sw1 ab.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
. Entfernen Sie alle Kabel vom SN2100 sw1-Switch, und verbinden Sie sie dann mit den gleichen Ports am SN2100 nsw2-Switch.
. Die ISL-Ports swp15 und swp16 zwischen den Switches sw1 und nsw2.
+
Die folgenden Befehle ermöglichen ISL-Ports swp15 und swp16 auf Switch sw1:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv set interface swp15-16 link state down*
cumulus@sw1:~$ *nv config apply*
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch sw1 aufstehen:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------- ----------------------
...
...
UP     swp15        100G  9216   BondMember  nsw2 (swp15)   Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  nsw2 (swp16)   Master: cluster_isl(UP)
----
+
Das folgende Beispiel zeigt, dass die ISL-Ports auf Switch nsw2 aktiv sind:

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP           Summary
-----  -----------  ----  -----  ----------  -------------  -----------------------
...
...
UP     swp15        100G  9216   BondMember  sw1 (swp15)    Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)    Master: cluster_isl(UP)
----
. Überprüfen Sie diesen Port `e3b` Ist auf allen Knoten aktiv:
+
`network port show -ipspace Cluster`

+
Die Ausgabe sollte wie folgt aussehen:

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node: node1
                                                                         Ignore
                                                   Speed(Mbps)  Health   Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper   Status   Status
--------- ------------ ---------------- ---- ----- ------------ -------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false


Node: node2
                                                                         Ignore
                                                   Speed(Mbps) Health    Health
Port      IPspace      Broadcast Domain Link MTU   Admin/Oper  Status    Status
--------- ------------ ---------------- ---- ----- ----------- --------- -------
e3a       Cluster      Cluster          up   9000  auto/100000  healthy  false
e3b       Cluster      Cluster          up   9000  auto/100000  healthy  false
----
. Die Cluster-Ports auf jedem Node sind nun aus Sicht der Nodes mit Cluster-Switches auf die folgende Weise verbunden:
+
[listing, subs="+quotes"]
----
cluster1::*> *network device-discovery show -protocol lldp*
Node/       Local  Discovered
Protocol    Port   Device (LLDP: ChassisID)  Interface     Platform
----------- ------ ------------------------- ------------  ----------------
node1      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp3          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp3          -
node2      /lldp
            e3a    sw1  (b8:ce:f6:19:1a:7e)   swp4          -
            e3b    nsw2 (b8:ce:f6:19:1b:b6)   swp4          -
----
. Vergewissern Sie sich, dass alle Node-Cluster-Ports aktiv sind:
+
`nv show interface`

+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv show interface*

State  Name         Spd   MTU    Mode        LLDP              Summary
-----  -----------  ----  -----  ----------  ----------------- ----------------------
...
...
UP     swp3         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp4         100G  9216   Trunk/L2                      Master: bridge(UP)
UP     swp15        100G  9216   BondMember  sw1 (swp15)       Master: cluster_isl(UP)
UP     swp16        100G  9216   BondMember  sw1 (swp16)       Master: cluster_isl(UP)
----
. Vergewissern Sie sich, dass beide Knoten jeweils eine Verbindung zu jedem Switch haben:
+
`nv show interface lldp`

+
Das folgende Beispiel zeigt die entsprechenden Ergebnisse für beide Switches:

+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1              e3a
swp4       100G   Trunk/L2    node2              e3a
swp15      100G   BondMember  nsw2               swp15
swp16      100G   BondMember  nsw2               swp16


cumulus@nsw2:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost         RemotePort
---------  -----  ----------  -----------------  -----------
swp3       100G   Trunk/L2    node1                e3b
swp4       100G   Trunk/L2    node2                e3b
swp15      100G   BondMember  sw1                swp15
swp16      100G   BondMember  sw1                swp16
----
. Aktivieren Sie die automatische Zurücksetzung auf den Cluster-LIFs:
+
`cluster1::*> network interface modify -vserver Cluster -lif * -auto-revert true`

. Bringen Sie auf Switch nsw2 die Ports an, die mit den Netzwerkports der Knoten verbunden sind.
+
[listing, subs="+quotes"]
----
cumulus@nsw2:~$ *nv set interface swp1-14 link state up*
cumulus@nsw2:~$ *nv config apply*
----
. Zeigen Sie Informationen über die Nodes in einem Cluster an:
+
`cluster show`

+
Dieses Beispiel zeigt, dass der Zustand des Node für Node 1 und node2 in diesem Cluster „true“ lautet:

+
[listing, subs="+quotes"]
----
cluster1::*> *cluster show*

Node          Health  Eligibility
------------- ------- ------------
node1         true    true
node2         true    true
----
. Vergewissern Sie sich, dass alle physischen Cluster-Ports aktiv sind:
+
`network port show ipspace Cluster`

+
[listing, subs="+quotes"]
----
cluster1::*> *network port show -ipspace Cluster*

Node node1                                                               Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace     Broadcast Domain  Link  MTU   Admin/Oper  Status   Status
--------- ----------- ----------------- ----- ----- ----------- -------- ------
e3a       Cluster     Cluster           up    9000  auto/10000  healthy  false
e3b       Cluster     Cluster           up    9000  auto/10000  healthy  false

Node: node2
                                                                         Ignore
                                                    Speed(Mbps) Health   Health
Port      IPspace      Broadcast Domain Link  MTU   Admin/Oper  Status   Status
--------- ------------ ---------------- ----- ----- ----------- -------- ------
e3a       Cluster      Cluster          up    9000  auto/10000  healthy  false
e3b       Cluster      Cluster          up    9000  auto/10000  healthy  false
----


--
====


=== Schritt 3: Überprüfen Sie die Konfiguration

[role="tabbed-block"]
====
.Cumulus Linux 4.4.3
--
. Vergewissern Sie sich, dass das Cluster-Netzwerk ordnungsgemäß funktioniert.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *net show lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
.Cumulus Linux 5.x
--
. Vergewissern Sie sich, dass das Cluster-Netzwerk ordnungsgemäß funktioniert.
+
[listing, subs="+quotes"]
----
cumulus@sw1:~$ *nv show interface lldp*

LocalPort  Speed  Mode        RemoteHost      RemotePort
---------  -----  ----------  --------------  -----------
swp3       100G   Trunk/L2    node1           e3a
swp4       100G   Trunk/L2    node2           e3a
swp15      100G   BondMember  nsw2            swp15
swp16      100G   BondMember  nsw2            swp16
----


--
====
. [[step2]] Ändern Sie die Berechtigungsebene zurück zu admin:
+
`set -privilege admin`

. Wenn Sie die automatische Case-Erstellung unterdrückt haben, aktivieren Sie es erneut, indem Sie eine AutoSupport Meldung aufrufen:
+
`system node autosupport invoke -node * -type all -message MAINT=END`



.Was kommt als Nächstes?
Nachdem Sie Ihre Schalter ausgetauscht haben, können Sie link:../switch-cshm/config-overview.html["Konfigurieren der Switch-Integritätsüberwachung"]Die
